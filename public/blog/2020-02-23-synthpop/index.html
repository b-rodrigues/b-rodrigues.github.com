<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8"  lang="en-us">
    <title>Synthetic micro-datasets: a promising middle ground between data privacy and data analysis - Econometrics and Free Software</title>
    <meta name="generator" content="Hugo 0.25.1" />

    
    <meta name="description" content="A blog about econometrics, free software, and R">
    
    <link rel="canonical" href="../../blog/2020-02-23-synthpop/">
    
    <meta name="author" content="Bruno Rodrigues">
    
    <meta name="generator" content="Hugo 0.25.1" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:url" content="/blog/2020-02-23-synthpop/">
    <meta property="og:title" content="Econometrics and Free Software">
    <meta property="og:image" content="/map[alt:Logo url:logo.png width:50 height:50]">
    <meta name="apple-mobile-web-app-title" content="Econometrics and Free Software">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <link rel="shortcut icon" type="image/x-icon" href="../../images/favicon.ico">
    <link rel="icon" type="image/x-icon" href="../../images/favicon.ico">

    
    <link rel="stylesheet" href="../../css/bootstrap.min.css" media="screen">
    <link rel="stylesheet" href="../../css/custom.css">
    <link rel="stylesheet" href="../../css/pygments.css">
    
    <link rel="stylesheet" href="../../css/jquery.fancybox.css?v=2.1.5" type="text/css" media="screen" />
    <link rel="stylesheet" href="../../css/helpers/jquery.fancybox-buttons.css?v=1.0.5" type="text/css" media="screen" />
  </head>
  <body>


<div class="row">
<div class="navbar navbar-default navbar-fixed-top">
<div class="container">
  <div class="navbar-header">
    <a href="../../" class="navbar-brand">Econometrics and Free Software</a>
    <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
      <span class="icon-bar"></span>
    </button>
  </div>
  <div class="navbar-collapse collapse" id="navbar-main">

    <ul class="nav navbar-nav navbar-right">
      <li><a href="https://www.buymeacoffee.com/brodriguesco">Donate</a></li>
      <li><a href="https://www.youtube.com/c/BrunoRodrigues1988">Youtube</a></li>
      <li><a href="https://github.com/b-rodrigues/">Github</a></li>
      <li><a href="https://twitter.com/brodriguesco/">Twitter</a></li>
    </ul>
  </div>
</div>

</div>

<div class="container">

  <div>
    <div class="row">
      <div class="col-lg-3 col-md-3 col-sm-4">
        

<div class="list-group table-of-contents">

  
    <a class="list-group-item" href=#><b>About Me</b></a>
    
    <div class="list-group">
      
      <a class="list-group-item" href="../../about/about/">Who am I?</a>
      
      <a class="list-group-item" href="../../about/projects/">Projects</a>
      
      <a class="list-group-item" href="../../about/research/">Research</a>
      
      <a class="list-group-item" href="../../about/software/">Software</a>
      
    </div>
    
  
    <a class="list-group-item" href=#><b>Blog</b></a>
    
    <div class="list-group">
      
      <a class="list-group-item" href="../../blog/2018-11-25-tidy_cv/">A tutorial on tidy cross-validation with R</a>
      
      <a class="list-group-item" href="../../blog/2018-11-03-nethack_analysis/">Analyzing NetHack data, part 1: What kills the players</a>
      
      <a class="list-group-item" href="../../blog/2018-11-10-nethack_analysis_part2/">Analyzing NetHack data, part 2: What players kill the most</a>
      
      <a class="list-group-item" href="../../blog/2019-02-04-newspapers_shiny_app_tutorial/">Building a shiny app to explore historical newspapers: a step-by-step guide</a>
      
      <a class="list-group-item" href="../../blog/2019-03-03-historical_vowpal/">Classification of historical newspapers content: a tutorial combining R, bash and Vowpal Wabbit, part 1</a>
      
      <a class="list-group-item" href="../../blog/2019-03-05-historical_vowpal_part2/">Classification of historical newspapers content: a tutorial combining R, bash and Vowpal Wabbit, part 2</a>
      
      <a class="list-group-item" href="../../blog/2019-06-20-tidy_eval_saga/">Curly-Curly, the successor of Bang-Bang</a>
      
      <a class="list-group-item" href="../../blog/2018-07-08-rob_stderr/">Dealing with heteroskedasticity; regression with robust standard errors using R</a>
      
      <a class="list-group-item" href="../../blog/2018-11-14-luxairport/">Easy time-series prediction with R: a tutorial with air traffic data from Lux Airport</a>
      
      <a class="list-group-item" href="../../blog/2018-10-05-ggplot2_purrr_officer/">Exporting editable plots from R to Powerpoint: making ggplot2 purrr with officer</a>
      
      <a class="list-group-item" href="../../blog/2019-04-28-diffindiff_part1/">Fast food, causality and R packages, part 1</a>
      
      <a class="list-group-item" href="../../blog/2019-05-04-diffindiff_part2/">Fast food, causality and R packages, part 2</a>
      
      <a class="list-group-item" href="../../blog/2019-05-18-xml2/">For posterity: install {xml2} on GNU/Linux distros</a>
      
      <a class="list-group-item" href="../../blog/2018-06-24-fun_ts/">Forecasting my weight with R</a>
      
      <a class="list-group-item" href="../../blog/2018-11-01-nethack/">From webscraping data to releasing it as an R package to share with the world: a full tutorial with data from NetHack</a>
      
      <a class="list-group-item" href="../../blog/2019-03-31-tesseract/">Get text from pdfs or images using OCR: a tutorial with {tesseract} and {magick}</a>
      
      <a class="list-group-item" href="../../blog/2018-06-10-scraping_pdfs/">Getting data from pdfs using the pdftools package</a>
      
      <a class="list-group-item" href="../../blog/2018-10-21-lux_elections/">Getting the data from the Luxembourguish elections out of Excel</a>
      
      <a class="list-group-item" href="../../blog/2018-09-11-human_to_machine/">Going from a human readable Excel file to a machine-readable csv with {tidyxl}</a>
      
      <a class="list-group-item" href="../../blog/2019-04-07-historical_newspaper_scraping_tesseract/">Historical newspaper scraping with {tesseract} and R</a>
      
      <a class="list-group-item" href="../../blog/2018-09-15-time_use/">How Luxembourguish residents spend their time: a small {flexdashboard} demo using the Time use survey data</a>
      
      <a class="list-group-item" href="../../blog/2018-04-14-playing_with_furrr/">Imputing missing values in parallel using {furrr}</a>
      
      <a class="list-group-item" href="../../blog/2019-06-12-intermittent/">Intermittent demand, Croston and Die Hard</a>
      
      <a class="list-group-item" href="../../blog/2019-01-04-newspapers/">Looking into 19th century ads from a Luxembourguish newspaper with R</a>
      
      <a class="list-group-item" href="../../blog/2019-01-13-newspapers_mets_alto/">Making sense of the METS and ALTO XML standards</a>
      
      <a class="list-group-item" href="../../blog/2018-12-15-lubridate_africa/">Manipulate dates easily with {lubridate}</a>
      
      <a class="list-group-item" href="../../blog/2019-02-10-stringr_package/">Manipulating strings with the {stringr} package</a>
      
      <a class="list-group-item" href="../../blog/2018-10-27-lux_elections_analysis/">Maps with pie charts on top of each administrative division: an example with Luxembourg&#39;s elections data</a>
      
      <a class="list-group-item" href="../../blog/2018-07-01-tidy_ive/">Missing data imputation and instrumental variables regression: the tidy approach</a>
      
      <a class="list-group-item" href="../../blog/2019-08-17-modern_r/">Modern R with the tidyverse is available on Leanpub</a>
      
      <a class="list-group-item" href="../../blog/2018-12-24-modern_objects/">Objects types and some useful R functions for beginners</a>
      
      <a class="list-group-item" href="../../blog/2019-03-20-pivot/">Pivoting data frames just got easier thanks to `pivot_wide()` and `pivot_long()`</a>
      
      <a class="list-group-item" href="../../blog/2018-12-30-reticulate/">R or Python? Why not both? Using Anaconda Python within R with {reticulate}</a>
      
      <a class="list-group-item" href="../../blog/2018-11-15-tidy_gridsearch/">Searching for the optimal hyper-parameters of an ARIMA model in parallel: the tidy gridsearch approach</a>
      
      <a class="list-group-item" href="../../blog/2018-12-27-fun_gganimate/">Some fun with {gganimate}</a>
      
      <a class="list-group-item" href="../../blog/2019-10-05-parallel_maxlik/">Split-apply-combine for Maximum Likelihood Estimation of a linear model</a>
      
      <a class="list-group-item" href="../../blog/2019-07-19-statmatch/">Statistical matching, or when one single data source is not enough</a>
      
      <a class="list-group-item" href="../../blog/2018-11-21-lux_castle/">The best way to visit Luxembourguish castles is doing data science &#43; combinatorial optimization</a>
      
      <a class="list-group-item" href="../../blog/2019-05-19-spacemacs/">The never-ending editor war (?)</a>
      
      <a class="list-group-item" href="../../blog/2018-09-08-steam_linux/">The year of the GNU&#43;Linux desktop is upon us: using user ratings of Steam Play compatibility to play around with regex and the tidyverse</a>
      
      <a class="list-group-item" href="../../blog/2019-01-31-newspapers_shiny_app/">Using Data Science to read 10 years of Luxembourguish newspapers from the 19th century</a>
      
      <a class="list-group-item" href="../../blog/2018-11-16-rgenoud_arima/">Using a genetic algorithm for the hyperparameter optimization of a SARIMA model</a>
      
      <a class="list-group-item" href="../../blog/2019-06-04-cosine_sim/">Using cosine similarity to find matching documents: a tutorial using Seneca&#39;s letters to his friend Lucilius</a>
      
      <a class="list-group-item" href="../../blog/2019-08-14-lpm/">Using linear models with binary dependent variables, a simulation study</a>
      
      <a class="list-group-item" href="../../blog/2018-12-21-tidyverse_pi/">Using the tidyverse for more than data manipulation: estimating pi with Monte Carlo methods</a>
      
      <a class="list-group-item" href="../../blog/2018-12-02-hyper-parameters/">What hyper-parameters are, and what to do with them; an illustration with ridge regression</a>
      
      <a class="list-group-item" href="../../blog/2019-09-03-disk_frame/">{disk.frame} is epic</a>
      
      <a class="list-group-item" href="../../blog/2018-04-15-announcing_pmice/">{pmice}, an experimental package for missing data imputation in parallel using {mice} and {furrr}</a>
      
      <a class="list-group-item" href="../../blog/2017-12-27-build_formulae/">Building formulae</a>
      
      <a class="list-group-item" href="../../blog/2017-11-14-peace_r/">Functional peace of mind</a>
      
      <a class="list-group-item" href="../../blog/2018-04-10-brotools_describe/">Get basic summary statistics for all the variables in a data frame</a>
      
      <a class="list-group-item" href="../../blog/2018-03-03-sparklyr_h2o_rsparkling/">Getting {sparklyr}, {h2o}, {rsparkling} to work together and some fun with bash</a>
      
      <a class="list-group-item" href="../../blog/2018-02-16-importing_30gb_of_data/">Importing 30GB of data into R with sparklyr</a>
      
      <a class="list-group-item" href="../../blog/2017-03-27-introducing_brotools/">Introducing brotools</a>
      
      <a class="list-group-item" href="../../blog/2018-01-03-lists_all_the_way/">It&#39;s lists all the way down</a>
      
      <a class="list-group-item" href="../../blog/2018-01-05-lists_all_the_way2/">It&#39;s lists all the way down, part 2: We need to go deeper</a>
      
      <a class="list-group-item" href="../../blog/2018-03-12-keep_trying/">Keep trying that api call with purrr::possibly()</a>
      
      <a class="list-group-item" href="../../blog/2017-06-19-dplyr-0-70-tutorial/">Lesser known dplyr 0.7* tricks</a>
      
      <a class="list-group-item" href="../../blog/2017-02-17-lesser_known_tricks/">Lesser known dplyr tricks</a>
      
      <a class="list-group-item" href="../../blog/2017-03-24-lesser_known_purrr/">Lesser known purrr tricks</a>
      
      <a class="list-group-item" href="../../blog/2017-03-29-make-ggplot2-purrr/">Make ggplot2 purrr</a>
      
      <a class="list-group-item" href="../../blog/2018-01-19-mapping_functions_with_any_cols/">Mapping a list of functions to a list of datasets with a list of columns as arguments</a>
      
      <a class="list-group-item" href="../../blog/2018-02-11-census-random_forest/">Predicting job search by training a random forest on an unbalanced dataset</a>
      
      <a class="list-group-item" href="../../blog/2017-12-17-teaching_tidyverse/">Teaching the tidyverse to beginners</a>
      
      <a class="list-group-item" href="../../blog/2017-08-27-why_tidyeval/">Why I find tidyeval useful</a>
      
      <a class="list-group-item" href="../../blog/2017-07-27-spread_rename_at/">tidyr::spread() and dplyr::rename_at() in action</a>
      
      <a class="list-group-item" href="../../blog/2017-10-26-margins_r/">Easy peasy STATA-like marginal effects with R</a>
      
      <a class="list-group-item" href="../../blog/2016-12-24-functional-programming-and-unit-testing-for-data-munging-with-r-available-on-leanpub/">Functional programming and unit testing for data munging with R available on Leanpub</a>
      
      <a class="list-group-item" href="../../blog/2017-02-17-how_to_use_jailbreakr/">How to use jailbreakr</a>
      
      <a class="list-group-item" href="../../blog/2017-01-07-my-free-book-has-a-cover/">My free book has a cover!</a>
      
      <a class="list-group-item" href="../../blog/2016-12-21-work-on-lists-of-datasets-instead-of-individual-datasets-by-using-functional-programming/">Work on lists of datasets instead of individual datasets by using functional programming</a>
      
      <a class="list-group-item" href="../../blog/2013-01-29-method-of-simulated-moments-with-r/">Method of Simulated Moments with R</a>
      
      <a class="list-group-item" href="../../blog/2012-12-11-new-website/">New website!</a>
      
      <a class="list-group-item" href="../../blog/2013-11-07-gmm-with-rmd/">Nonlinear Gmm with R - Example with a logistic regression</a>
      
      <a class="list-group-item" href="../../blog/2013-01-16-simulated-maximum-likelihood-with-r/">Simulated Maximum Likelihood with R</a>
      
      <a class="list-group-item" href="../../blog/2015-11-11-bootstrapping-did-with-r/">Bootstrapping standard errors for difference-in-differences estimation with R</a>
      
      <a class="list-group-item" href="../../blog/2016-06-21-careful-with-trycatch/">Careful with tryCatch</a>
      
      <a class="list-group-item" href="../../blog/2016-07-18-data-frame-columns-as-arguments-to-dplyr-functions/">Data frame columns as arguments to dplyr functions</a>
      
      <a class="list-group-item" href="../../blog/2015-02-22-export-r-output-to-file/">Export R output to a file</a>
      
      <a class="list-group-item" href="../../blog/2016-11-04-ive-started-writing-a-book-functional-programming-and-unit-testing-for-data-munging-with-r/">I&#39;ve started writing a &#39;book&#39;: Functional programming and unit testing for data munging with R</a>
      
      <a class="list-group-item" href="../../blog/2015-01-12-introduction-to-programming-econometrics-with-r/">Introduction to programming econometrics with R</a>
      
      <a class="list-group-item" href="../../blog/2016-07-30-merge-a-list-of-datasets-together/">Merge a list of datasets together</a>
      
      <a class="list-group-item" href="../../blog/2014-04-23-r-s4-rootfinding/">Object Oriented Programming with R: An example with a Cournot duopoly</a>
      
      <a class="list-group-item" href="../../blog/2014-11-11-benchmarks-r-blas-atlas-rro/">R, R with Atlas, R with OpenBLAS and Revolution R Open: which is fastest?</a>
      
      <a class="list-group-item" href="../../blog/2016-07-26-read-a-lot-of-datasets-at-once-with-r/">Read a lot of datasets at once with R</a>
      
      <a class="list-group-item" href="../../blog/2016-03-31-unit-testing-with-r/">Unit testing with R</a>
      
      <a class="list-group-item" href="../../blog/2015-05-03-update-introduction-r-programming/">Update to Introduction to programming econometrics with R</a>
      
      <a class="list-group-item" href="../../blog/2013-12-31-r-cas/">Using R as a Computer Algebra System with Ryacas</a>
      
    </div>
    
  

</div>

      </div>
      <div class="col-lg-9 col-md-9 col-sm-8">
        <div>
           <h1 id="main">Synthetic micro-datasets: a promising middle ground between data privacy and data analysis</h1>
           <span class="article-date">February 23, 2020</span>
        </div>
        <div style="text-align:center;">
<p><a href="https://twitter.com/scienceshitpost/status/1218199897654120449">
<img src="../../img/fake_car.png" title = "A purpoise can be assumed to be a kind of fake car."></a></p>
</div>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<div id="intro-the-need-for-microdata-and-the-risk-of-disclosure" class="section level2">
<h2>Intro: the need for microdata, and the risk of disclosure</h2>
<p>Survey and administrative data are essential for scientific research, however accessing such datasets
can be very tricky, or even impossible. In my previous job I was responsible for getting access to
such “scientific micro-datasets” from institutions like Eurostat.
In general, getting access to these micro datasets was only a question of filling out some forms
and signing NDAs. But this was true only because my previous employer was an accredited research entity.
Companies from the private sector or unaffiliated, individual, researchers cannot get access to
the microdata sets. This is because institutions that produce such datasets absolutely do not want
any type of personal information to be disclosed.</p>
<p>For instance, with the labour force survey, a National Statistical Institute (NSI) collects
information about wages, family structure, educational attainment and much more.
If, say, a politician would answer to the survey and his answers would leak to the public that would
be disastrous for NSIs. So this is why access is restricted to accredited research institutions.
You may be asking yourself, “how could the politicians answers leak? The data is anonymized!”
Indeed it is, but in some cases that may not be enough to ensure that information does not get
disclosed. Suppose that the dataset contains enough information to allow you to know for certain
that you found said politician, assume that this politician is a 43 year old man, has two children,
a PhD in theology and lives in Strassen, one of Luxembourg-City very nice neighborhoods. It would be quite easy to
find him in the dataset and then find out his wage.</p>
<p>To avoid this, researchers are required to perform output checking, which means going through the
set of outputs (summary tables, graphs, tables with regression coefficients…) and making sure that
it is not possible to find out individuals. For instance, in Luxembourg there are two companies in
the tobacco industry. Luxembourg’s NSI cannot release the total turnover
of the industry, because then company A would subtract its turnover from the total and find out its
competitor’s turnover. Now these are all hypothetical examples, and we might argue that the risk of
leakage is quite low, especially if NSIs make sure to lower the precision of the variables, by
providing age categories instead of the exact age for example. Or capping wages that exceed a certain
fixed amount.
In any case for now most NSIs don’t release micro data to the public, and this poses some challenges
for research. First of all, even for researchers, it would be great if the data was freely accessible.
It would allow research to go straight to data analysis and look at the structure of the data before
applying for access, with the risk of getting access to useless data.
And of course it would be great for the public at large to be able to freely access such data, for
educational purposes at the very least. It would also increase competition between research institutions
and the private sector when it comes to conducting studies using such data. Free access to the
microdata would level the playing field.
Now, some NSIs do release micro data to the public, see Eustat, the NSI from the Basque country,
an autonomous region of Spain. It is not clear to me if they also have more detailed data that is
only accessible to researchers, but the data they offer is already quite interesting.</p>
<p>A middle ground between only releasing data to researchers and making it completely freely accessible
is to create a synthetic dataset, which does not contain any of the original records, but which still
allows to perform meaningful analyses.</p>
<p>I’m not yet very familiar with the details of the procedure, but in this blog post I’ll use Eustat’s
microdata to generate a synthetic dataset. I’ll then perform the same analysis on both the original
dataset and the synthetic dataset. The dataset I’ll be using can be found
<a href="https://en.eustat.eus/estadisticas/tema_37/opt_0/tipo_11/temas.html">here</a>, and is called
<em>Population with relation to activity (PRA)</em>:</p>
<p><em>The Survey on the Population in Relation to Activity operation is a continuous source of
information on the characteristics and dynamics of the labour force of the Basque Country.
It records the relation to productive activity of the population resident in family households,
as well as the changes produced in labour situations; it produces indicators of conjunctural
variations in the evolution of the active population; it also estimates the degree of participation
of the population in economically non-productive activities. It offers information on the province
and capital level.</em></p>
<p>I’ll then compare the results of the analyses performed on the two datasets which will hopefully be
very similar. To create the synthetic dataset, I’ll be using the <code>{synthpop}</code> package. You can read
the detailed vignette <a href="https://cran.r-project.org/web/packages/synthpop/vignettes/synthpop.pdf">here - pdf warning -</a>.
First, let me perform some cleaning steps. There are four datasets included in the
archive. Let’s load them:</p>
<pre class="r"><code>library(tidyverse)
library(tidymodels)
library(readxl)
library(synthpop)

list_data &lt;- Sys.glob(&quot;MICRO*.csv&quot;)

dataset &lt;- map(list_data, read_csv2) %&gt;%
  bind_rows()

head(dataset)</code></pre>
<p>The columns are labeled in Spanish so I’m copy pasting the labels into Google translate and paste
them back into my script. I saved the English names into the english.rds object for posterity.
These steps are detailed in the next lines:</p>
<pre class="r"><code>dictionary &lt;- read_xlsx(&quot;Microdatos_PRA_2019/diseño_registro_microdatos_pra.xlsx&quot;, sheet=&quot;Valores&quot;,
                        col_names = FALSE)</code></pre>
<pre><code>## New names:
## * `` -&gt; ...1
## * `` -&gt; ...2
## * `` -&gt; ...3</code></pre>
<pre class="r"><code>col_names &lt;- dictionary %&gt;%
  filter(!is.na(...1)) %&gt;%
  dplyr::select(1:2)

# copy to clipboard, paste to google translate
# couldn&#39;t be bothered to use an api and google cloud or whatever
#clipr::write_clip(col_names$`...2`)

#english &lt;- clipr::read_clip()

english &lt;- readRDS(&quot;english_col_names.rds&quot;)

col_names$english &lt;- english

colnames(dataset) &lt;- col_names$english

dataset &lt;- janitor::clean_names(dataset)</code></pre>
<p>I now create a function that will perform the cleaning steps:</p>
<pre class="r"><code>basic_cleaning &lt;- function(dataset){
  dataset %&gt;%
  dplyr::filter(age %in% c(&quot;05&quot;, &quot;06&quot;, &quot;07&quot;, &quot;08&quot;, &quot;09&quot;, &quot;10&quot;, &quot;11&quot;)) %&gt;%
  dplyr::filter(!is.na(job_search)) %&gt;%  
  dplyr::select(territory, capital, sex, place_of_birth, age, nationality, level_of_studies_completed,
                job_search, main_occupation, type_of_contract, hours) %&gt;%
  dplyr::mutate_at(.vars = vars(-hours), .funs=as.factor)
}</code></pre>
</div>
<div id="putting-on-my-econometricians-hat" class="section level2">
<h2>Putting on my econometricians hat</h2>
<p>Let’s now suppose that I’m only interested in running a logistic regression:</p>
<pre class="r"><code>pra &lt;- basic_cleaning(dataset)

head(pra)</code></pre>
<pre><code>## # A tibble: 6 x 11
##   territory capital sex   place_of_birth age   nationality level_of_studie…
##   &lt;fct&gt;     &lt;fct&gt;   &lt;fct&gt; &lt;fct&gt;          &lt;fct&gt; &lt;fct&gt;       &lt;fct&gt;           
## 1 48        9       6     1              09    1           1               
## 2 48        9       1     1              09    1           2               
## 3 48        1       1     1              11    1           3               
## 4 48        1       6     1              10    1           3               
## 5 48        9       6     1              07    1           3               
## 6 48        9       1     1              09    1           1               
## # … with 4 more variables: job_search &lt;fct&gt;, main_occupation &lt;fct&gt;,
## #   type_of_contract &lt;fct&gt;, hours &lt;dbl&gt;</code></pre>
<pre class="r"><code>logit_model &lt;- glm(job_search ~ ., data = pra, family = binomial())

# Create a tidy dataset with the results of the regression
tidy_logit_model &lt;- tidy(logit_model, conf.int = TRUE) %&gt;%
  mutate(dataset = &quot;true&quot;)</code></pre>
<p>Let’s now take a look at the coefficients, by plotting their value along with their confidence
intervals:</p>
<pre class="r"><code>ggplot(tidy_logit_model, aes(x = term, y = estimate)) +
  geom_point(colour = &quot;#82518c&quot;) +
  geom_hline(yintercept = 0, colour = &quot;red&quot;) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), colour = &quot;#657b83&quot;) +
  brotools::theme_blog() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) </code></pre>
<p><img src="../../blog/2020-02-23-synthpop_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
<p>Ok, so now, how would the results change if I run the same analysis on the synthetic dataset? First,
I need to generate this synthetic dataset:</p>
<pre class="r"><code>my_seed &lt;- 1234

synthetic_data &lt;- syn(pra, seed = my_seed)</code></pre>
<pre><code>## Synthesis
## -----------
##  territory capital sex place_of_birth age nationality level_of_studies_completed job_search main_occupation type_of_contract
##  hours</code></pre>
<p>The synthetic data is generated by a single call to the <code>syn()</code> function included in the <code>{synthpop}</code>
package. Let’s take a look at the generated object:</p>
<pre class="r"><code>synthetic_data</code></pre>
<pre><code>## Call:
## ($call) syn(data = pra, seed = my_seed)
## 
## Number of synthesised data sets: 
## ($m)  1 
## 
## First rows of synthesised data set: 
## ($syn)
##   territory capital sex place_of_birth age nationality
## 1        48       9   1              1  06           1
## 2        01       9   6              3  09           1
## 3        48       3   1              1  08           1
## 4        48       9   6              1  11           1
## 5        20       2   6              1  09           1
## 6        48       1   6              1  11           1
##   level_of_studies_completed job_search main_occupation type_of_contract hours
## 1                          3          N               2                1    40
## 2                          1          S               9                6    10
## 3                          1          N               6             &lt;NA&gt;    32
## 4                          2          N               4                1    32
## 5                          3          N               5             &lt;NA&gt;    40
## 6                          1          S               7             &lt;NA&gt;    NA
## ...
## 
## Synthesising methods: 
## ($method)
##                  territory                    capital 
##                   &quot;sample&quot;                     &quot;cart&quot; 
##                        sex             place_of_birth 
##                     &quot;cart&quot;                     &quot;cart&quot; 
##                        age                nationality 
##                     &quot;cart&quot;                     &quot;cart&quot; 
## level_of_studies_completed                 job_search 
##                     &quot;cart&quot;                     &quot;cart&quot; 
##            main_occupation           type_of_contract 
##                     &quot;cart&quot;                     &quot;cart&quot; 
##                      hours 
##                     &quot;cart&quot; 
## 
## Order of synthesis: 
## ($visit.sequence)
##                  territory                    capital 
##                          1                          2 
##                        sex             place_of_birth 
##                          3                          4 
##                        age                nationality 
##                          5                          6 
## level_of_studies_completed                 job_search 
##                          7                          8 
##            main_occupation           type_of_contract 
##                          9                         10 
##                      hours 
##                         11 
## 
## Matrix of predictors: 
## ($predictor.matrix)
##                            territory capital sex place_of_birth age nationality
## territory                          0       0   0              0   0           0
## capital                            1       0   0              0   0           0
## sex                                1       1   0              0   0           0
## place_of_birth                     1       1   1              0   0           0
## age                                1       1   1              1   0           0
## nationality                        1       1   1              1   1           0
## level_of_studies_completed         1       1   1              1   1           1
## job_search                         1       1   1              1   1           1
## main_occupation                    1       1   1              1   1           1
## type_of_contract                   1       1   1              1   1           1
## hours                              1       1   1              1   1           1
##                            level_of_studies_completed job_search
## territory                                           0          0
## capital                                             0          0
## sex                                                 0          0
## place_of_birth                                      0          0
## age                                                 0          0
## nationality                                         0          0
## level_of_studies_completed                          0          0
## job_search                                          1          0
## main_occupation                                     1          1
## type_of_contract                                    1          1
## hours                                               1          1
##                            main_occupation type_of_contract hours
## territory                                0                0     0
## capital                                  0                0     0
## sex                                      0                0     0
## place_of_birth                           0                0     0
## age                                      0                0     0
## nationality                              0                0     0
## level_of_studies_completed               0                0     0
## job_search                               0                0     0
## main_occupation                          0                0     0
## type_of_contract                         1                0     0
## hours                                    1                1     0</code></pre>
<p>As you can see, <code>synthetic_data</code> is a list with several elements. The data is inside the <code>syn</code> element.
Let’s extract it, and perform the same analysis from before:</p>
<pre class="r"><code>syn_pra &lt;- synthetic_data$syn

head(syn_pra)</code></pre>
<pre><code>##   territory capital sex place_of_birth age nationality
## 1        48       9   1              1  06           1
## 2        01       9   6              3  09           1
## 3        48       3   1              1  08           1
## 4        48       9   6              1  11           1
## 5        20       2   6              1  09           1
## 6        48       1   6              1  11           1
##   level_of_studies_completed job_search main_occupation type_of_contract hours
## 1                          3          N               2                1    40
## 2                          1          S               9                6    10
## 3                          1          N               6             &lt;NA&gt;    32
## 4                          2          N               4                1    32
## 5                          3          N               5             &lt;NA&gt;    40
## 6                          1          S               7             &lt;NA&gt;    NA</code></pre>
<pre class="r"><code>syn_pra &lt;- basic_cleaning(syn_pra)

logit_model_syn &lt;- glm(job_search ~ ., data = syn_pra, family = binomial())

tidy_logit_syn &lt;- tidy(logit_model_syn, conf.int = TRUE) %&gt;%
  mutate(dataset = &quot;syn&quot;)

ggplot(tidy_logit_syn, aes(x = term, y = estimate)) +
  geom_point(colour = &quot;#82518c&quot;) +
  geom_hline(yintercept = 0, colour = &quot;red&quot;) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), colour = &quot;#657b83&quot;) +
  brotools::theme_blog() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) </code></pre>
<p><img src="../../blog/2020-02-23-synthpop_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>To ease the comparison between the coefficients of the model, let’s create a single graph:</p>
<pre class="r"><code>coeff_models &lt;- bind_rows(list(tidy_logit_model, tidy_logit_syn))

ggplot(coeff_models, aes(x = term, y = estimate, colour = dataset)) +
  geom_point() +
  geom_hline(yintercept = 0) +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  brotools::theme_blog() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) </code></pre>
<p><img src="../../blog/2020-02-23-synthpop_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>This is quite interesting; generally, there is quite some overlap between the synthetic data and
the real data! There are some differences though, for instance, <code>main_occupation6</code> is significant
with the synthetic data, but is not with the real data. There’s the possibility to generate more
than one synthetic dataset, which would very likely reduce the noise.</p>
</div>
<div id="putting-on-my-data-scientist-hat" class="section level2">
<h2>Putting on my data scientist hat</h2>
<p>Now let’s suppose that I am only interested into prediction. For this, I am going to split my dataset
into a training and testing set, then run a logistic regression and a random forest, assess the
models’ performance with 10-fold cross validation. I’ll do this on both the real and the synthetic
data. To perform the analysis, I’ll be using the <code>{tidymodels}</code> framework; I’m going to explain
the code that follows line by line, because I’ll very likely write a blog post focusing on <code>{tidymodels}</code>
soon.</p>
<p>So, let’s write a function that does exactly what I explained above:</p>
<pre class="r"><code>training_and_evaluating &lt;- function(dataset){

  pra_split &lt;- initial_split(dataset, prop = 0.8)
  
  pra_train &lt;- training(pra_split)
  pra_test &lt;- testing(pra_split)
  
  pra_cv_splits &lt;- vfold_cv(pra_train, v = 10)
  
  preprocess &lt;- recipe(job_search ~ ., data = pra) %&gt;%
    step_knnimpute(all_predictors())
  
  logit_pra &lt;- logistic_reg() %&gt;%
    set_engine(&quot;glm&quot;)
  
  fitted_logit &lt;- fit_resamples(preprocess,
                                model = logit_pra,
                                resamples = pra_cv_splits,
                                control = control_resamples(save_pred = TRUE))
  
  metric_logit &lt;- fitted_logit$.metrics %&gt;%
    bind_rows() %&gt;%
    group_by(.metric) %&gt;%
    summarise_at(.vars = vars(.estimate), .funs = lst(mean, sd)) %&gt;%
    mutate(model = &quot;logit&quot;)
  
  rf_pra &lt;- rand_forest(mode = &quot;classification&quot;) %&gt;%
    set_engine(engine = &quot;ranger&quot;)
  
  fitted_forest &lt;- fit_resamples(preprocess,
                                model = rf_pra,
                                resamples = pra_cv_splits,
                                control = control_resamples(save_pred = TRUE))
  
  metric_forest &lt;- fitted_forest$.metrics %&gt;%
    bind_rows() %&gt;%
    group_by(.metric) %&gt;%
    summarise_at(.vars = vars(.estimate), .funs = lst(mean, sd)) %&gt;%
    mutate(model = &quot;forest&quot;)


  bind_rows(list(metric_logit, metric_forest))
}</code></pre>
<p>Now I can run this function on both the real and the synthetic data, and look at the performance
of the logistic regression and of the random forest:</p>
<pre class="r"><code>true_data_performance &lt;- training_and_evaluating(pra)

syn_data_performance &lt;- training_and_evaluating(syn_pra)</code></pre>
<pre class="r"><code>true_data_performance</code></pre>
<pre><code>## # A tibble: 4 x 4
##   .metric   mean      sd model 
##   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; 
## 1 accuracy 0.882 0.00816 logit 
## 2 roc_auc  0.708 0.0172  logit 
## 3 accuracy 0.907 0.00619 forest
## 4 roc_auc  0.879 0.0123  forest</code></pre>
<pre class="r"><code>syn_data_performance</code></pre>
<pre><code>## # A tibble: 4 x 4
##   .metric   mean      sd model 
##   &lt;chr&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;chr&gt; 
## 1 accuracy 0.882 0.00758 logit 
## 2 roc_auc  0.691 0.0182  logit 
## 3 accuracy 0.899 0.00615 forest
## 4 roc_auc  0.857 0.0124  forest</code></pre>
<p>The performance is pretty much the same!</p>
<p>Generating synthetic data is a very promising approach, that I certainly will be using more; I think
that such approaches can also be very interesting in the private sector (not only to ease access
to microdata for researchers) especially within large
companies. For instance, it can happen that the data owners from say, an insurance company, are
not very keen on sharing sensitive client information with their data scientists. However, by generating
a synthetic dataset and sharing the synthetic data with their data science team, the data owners
avoid any chance of disclosure of sensitive information, while at the same time allowing their
data scientists to develop interesting analyses or applications on the data!</p>
<p>Hope you enjoyed! If you found this blog post useful, you might want to follow
me on <a href="https://www.twitter.com/brodriguesco">twitter</a> for blog post updates and watch my
<a href="https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ">youtube channel</a>. If you want to support
my blog and channel, you could <a href="https://www.buymeacoffee.com/brodriguesco">buy me an espresso</a> or
<a href="https://www.paypal.me/brodriguesco">paypal.me</a>, or buy my ebook on <a href="https://leanpub.com/modern_tidyverse">Leanpub</a>.</p>
<style>.bmc-button img{width: 27px !important;margin-bottom: 1px !important;box-shadow: none !important;border: none !important;vertical-align: middle !important;}.bmc-button{line-height: 36px !important;height:37px !important;text-decoration: none !important;display:inline-flex !important;color:#ffffff !important;background-color:#272b30 !important;border-radius: 3px !important;border: 1px solid transparent !important;padding: 1px 9px !important;font-size: 22px !important;letter-spacing:0.6px !important;box-shadow: 0px 1px 2px rgba(190, 190, 190, 0.5) !important;-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;margin: 0 auto !important;font-family:'Cookie', cursive !important;-webkit-box-sizing: border-box !important;box-sizing: border-box !important;-o-transition: 0.3s all linear !important;-webkit-transition: 0.3s all linear !important;-moz-transition: 0.3s all linear !important;-ms-transition: 0.3s all linear !important;transition: 0.3s all linear !important;}.bmc-button:hover, .bmc-button:active, .bmc-button:focus {-webkit-box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;text-decoration: none !important;box-shadow: 0px 1px 2px 2px rgba(190, 190, 190, 0.5) !important;opacity: 0.85 !important;color:#82518c !important;}</style>
<p><link href="https://fonts.googleapis.com/css?family=Cookie" rel="stylesheet"><a class="bmc-button" target="_blank" href="https://www.buymeacoffee.com/brodriguesco"><img src="https://www.buymeacoffee.com/assets/img/BMC-btn-logo.svg" alt="Buy me an Espresso"><span style="margin-left:5px">Buy me an Espresso</span></a></p>
</div>

      </div>
    </div>
  <div class="row">
    <div class="col-lg-9 col-md-9 col-sm-8 col-lg-offset-3 col-md-offset-3">
    <footer>
  <div class="row">
    <div class="col-lg-12">
      <p>Copyright 2020. <a> Bruno Rodrigues</a> </p>
      <p>Made with the HUGO theme <a href="https://github.com/adejoux/hugo-darkdoc-theme" rel="nofollow">darkdoc</a>.</p>
    </div>
  </div>
</footer>

</body>

    </div>
  </div>

</div>
</html>
<script>

  var api_url = '';

</script>
<script src="//code.jquery.com/jquery-2.2.3.min.js"></script>
<script src="../../js/application.js"></script>
<script type="text/javascript" src="../../js/jquery.fancybox.pack.js?v=2.1.5"></script>
<script type="text/javascript" src="../../js/helpers/jquery.fancybox-thumbs.js?v=1.0.7"></script>
<script type="text/javascript" src="../../js/helpers/jquery.fancybox-buttons.js?v=1.0.5"></script>
<script type="text/javascript" src="../../js/helpers/jquery.fancybox-media.js?v=1.0.6"></script>
<script type="text/javascript">
  $(document).ready(function() {
    $(".fancybox").fancybox();
  });
</script>

